# Content Vault Implementation Guide

## ‚úÖ What's Been Implemented

### 1. Database Schema
- **ContentItem model** added to Prisma schema with fields for:
  - Content metadata (title, type, status, wordCount)
  - Text content (summary, transcript, rawText)
  - Media info (thumbnail, source, duration, fileUrl)
  - Processing status and error handling
  - Tags and metadata storage

### 2. API Routes Created

#### `/api/content/upload` (POST)
- Handles file uploads (audio, video, text files)
- Validates file types
- Creates database records
- Queues processing jobs

#### `/api/content/transcribe` (POST)
- Transcribes audio/video using OpenAI Whisper API
- Extracts audio from video files
- Generates summaries
- Updates content status

#### `/api/content/scrape` (POST)
- Scrapes content from URLs
- Extracts text from HTML
- Generates summaries
- Extracts metadata (title, thumbnail)

#### `/api/content/podcast` (POST)
- Processes podcast links
- Fetches RSS feeds
- Extracts audio URLs
- Queues transcription

#### `/api/content` (GET/POST)
- GET: Fetches all content items for a user
- POST: Creates text content directly

### 3. UI Components

#### `UploadForm.tsx`
- Unified upload form for all content types
- Handles file uploads, URL input, and text input
- Shows upload progress and errors
- Integrates with API routes

#### Updated `ContentVaultPage.tsx`
- Fetches real data from API
- Real-time polling for processing items
- Integrated upload forms
- Error handling

## üîß Configuration Required

### 1. Environment Variables

Add to your `.env` file:

```env
# OpenAI API Key (for Whisper transcription)
OPENAI_API_KEY=sk-your-openai-api-key

# Database URL (already configured)
DATABASE_URL=your-postgresql-connection-string

# App URL (for internal API calls)
NEXT_PUBLIC_APP_URL=http://localhost:3000
```

### 2. Database Migration

Run Prisma migrations to create the ContentItem table:

```bash
npm run db:push
# or
npx prisma migrate dev
```

### 3. File Storage

**Current Status:** Files are stored with placeholder URLs. You need to implement actual file storage.

**Options:**
- **Supabase Storage** (recommended if using Supabase)
- **AWS S3**
- **Cloudinary**
- **Vercel Blob Storage**

**Implementation Steps:**
1. Update `/app/api/content/upload/route.ts` to upload files to your storage
2. Update the `fileUrl` field to use actual storage URLs
3. Update `/app/api/content/transcribe/route.ts` to fetch files from storage

### 4. Authentication Integration

**Current Status:** Uses placeholder `userId = "user-1"`

**To Fix:**
1. Implement authentication (NextAuth.js, Clerk, etc.)
2. Update `ContentVaultPage.tsx` to get userId from session:
   ```typescript
   // Example with NextAuth
   const { data: session } = useSession()
   const userId = session?.user?.id
   ```
3. Update all API routes to get userId from session/auth headers

### 5. Video Processing

**Current Status:** Video transcription assumes audio extraction is done

**To Implement:**
- Use `ffmpeg` or similar to extract audio from video files
- Install: `npm install fluent-ffmpeg` or use a service like Cloudinary
- Update `/app/api/content/transcribe/route.ts` to extract audio first

### 6. Enhanced Summarization

**Current Status:** Uses simple text extraction (first 3 sentences)

**To Improve:**
- Use OpenAI GPT to generate better summaries
- Update `generateSummary()` functions in API routes
- Example:
  ```typescript
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: `Summarize: ${text}` }],
    }),
  })
  ```

### 7. Supabase Vector DB (Optional)

For semantic search and embeddings:

1. Install Supabase client:
   ```bash
   npm install @supabase/supabase-js
   ```

2. Create embeddings table in Supabase
3. Generate embeddings using OpenAI embeddings API
4. Store in Supabase vector DB
5. Implement semantic search

## üöÄ Next Steps

1. **Set up file storage** - Choose and configure storage provider
2. **Add authentication** - Integrate auth system
3. **Configure OpenAI API** - Add API key to `.env`
4. **Run database migration** - Create ContentItem table
5. **Test upload flow** - Try uploading different content types
6. **Add video processing** - Implement audio extraction
7. **Enhance AI features** - Improve summaries with GPT

## üìù Testing Checklist

- [ ] Upload audio file (MP3, WAV)
- [ ] Upload video file (MP4)
- [ ] Paste URL and scrape content
- [ ] Add podcast link
- [ ] Paste text/notes
- [ ] View content details
- [ ] Reprocess failed items
- [ ] Filter by type/status
- [ ] Delete content items

## üêõ Known Limitations

1. **File Storage:** Currently uses placeholder URLs
2. **Video Processing:** Audio extraction not implemented
3. **Authentication:** Uses placeholder userId
4. **Summarization:** Basic text extraction (not AI-powered)
5. **Podcast Processing:** Limited RSS feed parsing
6. **Error Handling:** Basic error messages

## üí° Suggestions for Production

1. **Job Queue:** Use BullMQ or similar for async processing
2. **Webhooks:** Notify users when processing completes
3. **Rate Limiting:** Add rate limits to API routes
4. **File Validation:** More robust file type checking
5. **Caching:** Cache frequently accessed content
6. **Analytics:** Track content usage and processing times

